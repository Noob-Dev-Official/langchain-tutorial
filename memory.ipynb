{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1406d7b0-5fcf-454a-9ad9-2066cc80b0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alhudam/Desktop/projects/llm-tutorial/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7a32ea-8649-424e-889b-c06ac0019dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5acffb-b7f0-4a0d-9c7e-12be414f719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ee125ba-f9a3-4bc7-9630-318d2147540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258fca7c-55ff-4e02-9aea-7cf01bef82e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ddef5c-cb47-47ca-bc02-54a6c7770a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: what is 1 + 1\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1 + 1 equals 2.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is 1 + 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca90520a-9073-4617-b842-fbe079f434f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: what is 1 + 1\n",
      "AI: 1 + 1 equals 2.\n",
      "Human: what is my name\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ce4a86-a397-49cd-a9ba-c67a2c686756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: what is 1 + 1\n",
      "AI: 1 + 1 equals 2.\n",
      "Human: what is my name\n",
      "AI: Your name is Andrew.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3d133ee-a93e-4a1e-a7c7-9ec69b2264be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Andrew\\nAI: Hello Andrew! It's nice to meet you. How can I assist you today?\\nHuman: what is 1 + 1\\nAI: 1 + 1 equals 2.\\nHuman: what is my name\\nAI: Your name is Andrew.\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92b93df3-3f5e-48d7-a286-2f6f7b492226",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},{\"output\": \"whatsup\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a105ae0-146e-42be-b0b9-896f28322b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: what is 1 + 1\n",
      "AI: 1 + 1 equals 2.\n",
      "Human: what is my name\n",
      "AI: Your name is Andrew.\n",
      "Human: Hi\n",
      "AI: whatsup\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd026d-d3b1-43ad-941d-b513e5a75470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c891e-060b-48f6-8134-7271a0fe1725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538210c1-4aa2-4859-89f7-6ee33476ddc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c779d53a-5b60-4b8e-9c40-c911df66bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "860a1864-a863-4b21-bbbd-4bdf66a155f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1) # remember one coversation exchange (k=1), one from human and one from AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ec2a0d0-5633-4acb-9d12-27650ad8e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},{\"output\": \"whatsup\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "887d4266-20a7-425b-9bf7-ccedc772e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"nothing much, just hanging\"},{\"output\": \"nice\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccf3342c-115b-46c5-8527-380b35365cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: nothing much, just hanging\\nAI: nice'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "837affbe-e529-424d-aa6f-cdd0b9ce3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e03c358-0f02-4e55-a5a9-6aa97b42580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: what is 1 + 1\n",
      "AI: 1 + 1 equals 2.\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1532383b-2554-44a6-8a2a-7dddb75a7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: what is 1 + 1\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1 + 1 equals 2.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is 1 + 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d811e3e-656c-4cc7-b7cb-035f1ad863a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: what is 1 + 1\n",
      "AI: 1 + 1 equals 2.\n",
      "Human: what is my name\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682da7b0-153e-4d4e-9908-f7ad7130e275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c03e319-1c96-4cc8-923d-9fa30f207a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d774886e-c9bd-43d3-be16-27e31a0c05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5145edb1-da22-45f5-95ec-6ba5ee00c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07378fc9-55bf-45c9-9c43-78d8d47953b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},{\"output\": \"whatsup\"})\n",
    "memory.save_context({\"input\": \"Hi\"},{\"output\": \"whatsup\"})\n",
    "memory.save_context({\"input\": \"Hi\"},{\"output\": \"whatsup\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7bd0140-2ebb-4e02-afb2-48fd5c1a514b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8a945-ce69-4498-8fac-eeb0430c3628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d093e950-6b9f-4ff0-9376-aede0695b93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064b976-63b7-47cb-a714-fda2fbe0c016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3e760d2-62af-4287-a635-2be302ed52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "35c16fa1-b4b8-4cf6-beea-af60b6525354",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = \"There is a meeting at 8am with your product team \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "project will go quickly because LangChain is such a powerful tool \\\n",
    "At noon, lunch at the italian restaurant with the customer who wants to buy our product and who came from over an hour away to meet us\\\n",
    "Be sure to bring your laptop to show the latest LLM demo\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e597c9a-49d0-4475-8354-cbb385ebddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},{\"output\": \"whatsup\"})\n",
    "memory.save_context({\"input\": \"nothing much, just hanging\"},{\"output\": \"nice\"})\n",
    "memory.save_context({\"input\": \"What is my schedule today?\"},{\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "734be744-a342-4ea6-bb6c-75aa7acd3893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI engage in casual conversation. The human asks about their schedule for the day and the AI provides details about a meeting with the product team at 8am, emphasizing the need for a prepared PowerPoint presentation. The AI also mentions a lunch meeting with a customer who traveled a long distance to meet them, highlighting the importance of showcasing the latest LLM demo.'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77c9fb88-0c44-483a-8f56-69d8318d2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3094ef7c-2823-4ec3-9631-9b560ce27cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI engage in casual conversation. The human asks about their schedule for the day and the AI provides details about a meeting with the product team at 8am, emphasizing the need for a prepared PowerPoint presentation. The AI also mentions a lunch meeting with a customer who traveled a long distance to meet them, highlighting the importance of showcasing the latest LLM demo.\n",
      "Human: what would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A good demo to show during the lunch meeting with the customer would be the latest version of our LLM (Long Distance Laser Measurement) technology. This demo showcases the accuracy and precision of our product, highlighting its ability to measure distances accurately over long distances. It also demonstrates the advanced features and user-friendly interface of the LLM, making it an ideal choice to impress the customer and showcase the capabilities of our product.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"what would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3fc1735d-b4cc-466c-81d9-c0a895482aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI engage in casual conversation. The human asks about their schedule for the day and the AI provides details about a meeting with the product team at 8am, emphasizing the need for a prepared PowerPoint presentation. The AI also mentions a lunch meeting with a customer who traveled a long distance to meet them, highlighting the importance of showcasing the latest LLM demo. The human asks what would be a good demo to show, and the AI suggests the latest version of their LLM technology. This demo showcases the accuracy and precision of the product, highlighting its ability to measure distances accurately over long distances. It also demonstrates the advanced features and user-friendly interface of the LLM, making it an ideal choice to impress the customer and showcase the capabilities of the product.'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cf644-576e-4140-ae81-cee6dc1c745e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
